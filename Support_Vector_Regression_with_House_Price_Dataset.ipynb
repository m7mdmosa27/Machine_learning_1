{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Name: Mohamed Mosa Aboelftoh`\n",
    "\n",
    "`AI-Intake 2 Mansoura`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some preprossceing on data in the lab linear regreasion. i seved this cleaned version of House Price Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>1.5Fin</th>\n",
       "      <th>1.5Unf</th>\n",
       "      <th>...</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>GarageCars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238041</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.385266</td>\n",
       "      <td>0.549925</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.552863</td>\n",
       "      <td>0.418941</td>\n",
       "      <td>0.579828</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.533697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.358144</td>\n",
       "      <td>0.490516</td>\n",
       "      <td>0.534544</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274487</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.265211</td>\n",
       "      <td>0.549925</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.585896</td>\n",
       "      <td>0.593211</td>\n",
       "      <td>0.602513</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297836</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.117872</td>\n",
       "      <td>0.628213</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.555906</td>\n",
       "      <td>0.487404</td>\n",
       "      <td>0.449773</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402620</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.357435</td>\n",
       "      <td>0.549925</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.764968</td>\n",
       "      <td>0.780552</td>\n",
       "      <td>0.639100</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7  1.5Fin  1.5Unf  ...  1stFlrSF  \\\n",
       "0  2.0  3.0  0.0  2.0  2.0  2.0  3.0  1.0     0.0     0.0  ...  0.238041   \n",
       "1  2.0  3.0  0.0  0.0  3.0  3.0  1.0  1.0     0.0     0.0  ...  0.469248   \n",
       "2  2.0  0.0  0.0  2.0  2.0  2.0  2.0  1.0     0.0     0.0  ...  0.274487   \n",
       "3  3.0  0.0  2.0  0.0  3.0  2.0  3.0  2.0     0.0     0.0  ...  0.297836   \n",
       "4  2.0  0.0  0.0  2.0  2.0  2.0  0.0  1.0     0.0     0.0  ...  0.402620   \n",
       "\n",
       "   BsmtFullBath  BedroomAbvGr  BsmtFinSF1  MSSubClass    MoSold  GrLivArea  \\\n",
       "0           0.5         0.625    0.385266    0.549925  0.090909   0.552863   \n",
       "1           0.0         0.625    0.533697    0.000000  0.363636   0.358144   \n",
       "2           0.5         0.625    0.265211    0.549925  0.727273   0.585896   \n",
       "3           0.5         0.625    0.117872    0.628213  0.090909   0.555906   \n",
       "4           0.5         0.875    0.357435    0.549925  1.000000   0.764968   \n",
       "\n",
       "    LotArea  SalePrice  GarageCars  \n",
       "0  0.418941   0.579828         0.4  \n",
       "1  0.490516   0.534544         0.4  \n",
       "2  0.593211   0.602513         0.4  \n",
       "3  0.487404   0.449773         0.8  \n",
       "4  0.780552   0.639100         0.8  \n",
       "\n",
       "[5 rows x 125 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_house = pd.read_csv('content/Housses_train_dataset_cleaned.csv')\n",
    "df_house.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_col_without_label = list(set(df_house.columns.to_list())-set(['SalePrice']))\n",
    "X = df_house[all_col_without_label]\n",
    "X = pd.concat([pd.DataFrame(np.ones((X.shape[0],1))), X], axis=1).values\n",
    "Y = df_house['SalePrice'].values\n",
    "Y = Y.reshape((Y.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implemint The Model SVR "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is The best C ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where C is 0.2 the score is  0.7259713491963434\n",
      "Where C is 0.4 the score is  0.7206390287822411\n",
      "Where C is 0.6 the score is  0.7147988474569157\n",
      "Where C is 0.8 the score is  0.715652172823166\n",
      "Where C is 1.0 the score is  0.715652172823166\n",
      "Where C is 1.2 the score is  0.715652172823166\n",
      "Where C is 1.4 the score is  0.715652172823166\n",
      "Where C is 1.6 the score is  0.715652172823166\n",
      "Where C is 1.8 the score is  0.715652172823166\n",
      "Where C is 2.0 the score is  0.715652172823166\n",
      "Where C is 2.2 the score is  0.715652172823166\n",
      "Where C is 2.4 the score is  0.715652172823166\n",
      "Where C is 2.6 the score is  0.715652172823166\n",
      "Where C is 2.8 the score is  0.715652172823166\n",
      "Where C is 3.0 the score is  0.715652172823166\n",
      "Where C is 3.2 the score is  0.715652172823166\n",
      "Where C is 3.4 the score is  0.715652172823166\n",
      "Where C is 3.6 the score is  0.715652172823166\n",
      "Where C is 3.8 the score is  0.715652172823166\n"
     ]
    }
   ],
   "source": [
    "for c in range(1, 20):  # range from 0.2 to 5\n",
    "    c = c/5\n",
    "    Model = SVR(kernel='linear', C=c).fit(X_train, y_train)\n",
    "    y_pred = Model.predict(X_val)\n",
    "\n",
    "\n",
    "    print(f'Where C is {c} the score is ' ,Model.score(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What is the best polynomial degree d, the best C ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_of_C(degree = 1):\n",
    "    c_params = {}\n",
    "    for c in range(1, 11):  # range from 0.2 to 5\n",
    "        c = c/5\n",
    "        Model = SVR(kernel='poly', degree=degree, C=c, gamma='auto').fit(X_train, y_train)\n",
    "        # y_pred = Model.predict(X_val)\n",
    "        c_params[c] = Model.score(X_val, y_val)\n",
    "        \n",
    "    print(c_params)\n",
    "    max_score = max(c_params.values())\n",
    "    c = [k for k, v in c_params.items() if v == max_score][0]\n",
    "    return c, max_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_of_dgree():\n",
    "    deg_param = {}\n",
    "    for deg in range(1,11):\n",
    "        print('Degree = ', deg, ' every c with the best scor ++>')\n",
    "        deg_param[deg] = best_of_C(degree = deg)\n",
    "    \n",
    "        \n",
    "    max_score = max(np.array(list(deg_param.values()))[:,1])\n",
    "    best = [[k, v[0]] for k, v in deg_param.items() if v[1] == max_score]\n",
    "    best_c = best[0][1]\n",
    "    best_degree = best[0][0]\n",
    "    print( f'\\n\\nThe Best C is {best_c} and  the best degree is {best_degree} which it has max score = {max_score} '  )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree =  1  every c with the best scor ++>\n",
      "{0.2: 0.688162866533715, 0.4: 0.7181640790407586, 0.6: 0.7303770024870784, 0.8: 0.7280838012819362, 1.0: 0.7294345532382098, 1.2: 0.7274046868629072, 1.4: 0.723946348089461, 1.6: 0.7190354780194219, 1.8: 0.7154930536576534, 2.0: 0.7125859862699646}\n",
      "Degree =  2  every c with the best scor ++>\n",
      "{0.2: 0.6696361798965464, 0.4: 0.7068650135539827, 0.6: 0.7159401184728176, 0.8: 0.7212381427706789, 1.0: 0.7181334334205126, 1.2: 0.7175888008601399, 1.4: 0.714910051282232, 1.6: 0.7137825237067468, 1.8: 0.7136617293503501, 2.0: 0.7145722557872918}\n",
      "Degree =  3  every c with the best scor ++>\n",
      "{0.2: 0.6107896959181318, 0.4: 0.6560807561201973, 0.6: 0.671089920388119, 0.8: 0.6801276282265771, 1.0: 0.6898286390152957, 1.2: 0.6943044646912138, 1.4: 0.6980940531262221, 1.6: 0.700220060864479, 1.8: 0.6999920243321489, 2.0: 0.6987091126696419}\n",
      "Degree =  4  every c with the best scor ++>\n",
      "{0.2: 0.5425944555424504, 0.4: 0.583381147572347, 0.6: 0.6068566169608289, 0.8: 0.6214934739654511, 1.0: 0.6327357752507183, 1.2: 0.6417392873657295, 1.4: 0.6470551061223999, 1.6: 0.6488992589080194, 1.8: 0.6521894473380423, 2.0: 0.6542829225255888}\n",
      "Degree =  5  every c with the best scor ++>\n",
      "{0.2: 0.4764951488126369, 0.4: 0.5210739826166317, 0.6: 0.5468810148488923, 0.8: 0.5640765366855955, 1.0: 0.572480011118818, 1.2: 0.5807071752957004, 1.4: 0.5881351871932659, 1.6: 0.594835879430615, 1.8: 0.5992196047742716, 2.0: 0.6019700151458582}\n",
      "Degree =  6  every c with the best scor ++>\n",
      "{0.2: 0.41125241224944986, 0.4: 0.45819637064097785, 0.6: 0.4850911787464669, 0.8: 0.5037591331793889, 1.0: 0.5121745966415359, 1.2: 0.5225996183574071, 1.4: 0.5299580319727584, 1.6: 0.5380634709624652, 1.8: 0.5448696021252065, 2.0: 0.5500698472213826}\n",
      "Degree =  7  every c with the best scor ++>\n",
      "{0.2: 0.3579944700194525, 0.4: 0.39719786955406067, 0.6: 0.4240523029648572, 0.8: 0.4427896920395624, 1.0: 0.4564004985391673, 1.2: 0.46528303058990994, 1.4: 0.47351909895560207, 1.6: 0.4790569294891006, 1.8: 0.48477509182234046, 2.0: 0.49039882458935324}\n",
      "Degree =  8  every c with the best scor ++>\n",
      "{0.2: 0.3056081678290975, 0.4: 0.35117629191160593, 0.6: 0.3708940306370253, 0.8: 0.38784823098377397, 1.0: 0.4029234559224192, 1.2: 0.41220768786759254, 1.4: 0.42123061039346954, 1.6: 0.42591060535319236, 1.8: 0.43089030365727043, 2.0: 0.43630215758879654}\n",
      "Degree =  9  every c with the best scor ++>\n",
      "{0.2: 0.26611425207171135, 0.4: 0.3021571277690228, 0.6: 0.32913603499992483, 0.8: 0.34642009284245956, 1.0: 0.356102701168477, 1.2: 0.36478673604550094, 1.4: 0.3718672544810778, 1.6: 0.3786680502210378, 1.8: 0.38575561617641363, 2.0: 0.39094032997402517}\n",
      "Degree =  10  every c with the best scor ++>\n",
      "{0.2: 0.23129617644129563, 0.4: 0.26460988041661004, 0.6: 0.28589654100338413, 0.8: 0.3007544849659799, 1.0: 0.31528792352834356, 1.2: 0.3250820296800958, 1.4: 0.33360663206649066, 1.6: 0.3391706364373387, 1.8: 0.34375008179911204, 2.0: 0.34780331770314243}\n",
      "\n",
      "\n",
      "The Best C is 0.6 and  the best degree is 1 which it has max score = 0.7303770024870784 \n"
     ]
    }
   ],
   "source": [
    "best_of_dgree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What is the best C, and the best Gamma Hyper-parameters ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with kernel RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gama =  0.0001  every c with the best scor ++>\n",
      "{0.2: 0.3725483764706742, 0.4: 0.4768723355955272, 0.6: 0.5208738559434414, 0.8: 0.5556925161559185, 1.0: 0.5726992849786601, 1.2: 0.5869347531122195, 1.4: 0.5952414560304344, 1.6: 0.6036477117672359, 1.8: 0.6110333689649863, 2.0: 0.6214040162729022, 2.2: 0.6299328138884563, 2.4: 0.6337582518749332, 2.6: 0.636562800306565, 2.8: 0.6395646789400893, 3.0: 0.6443142977392484, 3.2: 0.6463531904862531, 3.4: 0.6480710270353438, 3.6: 0.6513518951337378, 3.8: 0.6544373247774308, 4.0: 0.6580830903180576, 4.2: 0.6600839617737929, 4.4: 0.6618004080729176, 4.6: 0.6626317574246225, 4.8: 0.663749521450836}\n",
      "\n",
      "gama =  0.0002  every c with the best scor ++>\n",
      "{0.2: 0.47586477906943214, 0.4: 0.5554005008232531, 0.6: 0.586439048056126, 0.8: 0.6035560650529093, 1.0: 0.6206163077592969, 1.2: 0.6334448903087238, 1.4: 0.6394532807870674, 1.6: 0.6461669638962981, 1.8: 0.6509399957541873, 2.0: 0.6580290519482457, 2.2: 0.6615054593971238, 2.4: 0.6634166815862721, 2.6: 0.6663658921764131, 2.8: 0.6695336770939957, 3.0: 0.6730497348052514, 3.2: 0.6778392154101216, 3.4: 0.6821969735548303, 3.6: 0.6863070288843769, 3.8: 0.6868573769693164, 4.0: 0.6883542584616102, 4.2: 0.6898638911148978, 4.4: 0.6911989144362807, 4.6: 0.6936214396570577, 4.8: 0.6947215316506885}\n",
      "\n",
      "gama =  0.0003  every c with the best scor ++>\n",
      "{0.2: 0.5202323318487252, 0.4: 0.5867963553307707, 0.6: 0.6115797588959933, 0.8: 0.6332321788293845, 1.0: 0.6432578662205769, 1.2: 0.6509277764932495, 1.4: 0.6600818872386477, 1.6: 0.6636205312703961, 1.8: 0.6682280973599458, 2.0: 0.673083276526489, 2.2: 0.6798263891323061, 2.4: 0.6859677889538313, 2.6: 0.6874449163321485, 2.8: 0.689544942841876, 3.0: 0.6922187810150976, 3.2: 0.6946177771652395, 3.4: 0.6967855454182996, 3.6: 0.6988721146565728, 3.8: 0.7004949260102189, 4.0: 0.7023862123880993, 4.2: 0.7044120733083014, 4.4: 0.7070278072395157, 4.6: 0.7088770342722279, 4.8: 0.711272901291722}\n",
      "\n",
      "gama =  0.0004  every c with the best scor ++>\n",
      "{0.2: 0.5539117315999194, 0.4: 0.6028746553977189, 0.6: 0.6328622761878305, 0.8: 0.6456695863184461, 1.0: 0.6578861396110359, 1.2: 0.663188598921786, 1.4: 0.669305118921016, 1.6: 0.6773555360224889, 1.8: 0.6856890202548496, 2.0: 0.6879561198379418, 2.2: 0.6906698711595689, 2.4: 0.6944366092594505, 2.6: 0.6975034929396993, 2.8: 0.6995419763064948, 3.0: 0.7024063381064155, 3.2: 0.7053472679542578, 3.4: 0.7081596388508745, 3.6: 0.7109227153815704, 3.8: 0.7139263882162163, 4.0: 0.71718268128885, 4.2: 0.7196409194754472, 4.4: 0.7217175097207524, 4.6: 0.723234414500728, 4.8: 0.7251050593033855}\n",
      "\n",
      "gama =  0.0005  every c with the best scor ++>\n",
      "{0.2: 0.5724139036273259, 0.4: 0.6196377993758646, 0.6: 0.6432552411948635, 0.8: 0.6572506818614409, 1.0: 0.6644161726002229, 1.2: 0.6726347520946463, 1.4: 0.6837755193371107, 1.6: 0.6877589517896824, 1.8: 0.6915741150752611, 2.0: 0.695824228079021, 2.2: 0.6993962978436437, 2.4: 0.7017162604418258, 2.6: 0.7060874222102587, 2.8: 0.7092276287530349, 3.0: 0.7131821226553043, 3.2: 0.7164909641558888, 3.4: 0.7200875228162137, 3.6: 0.7223212577329904, 3.8: 0.7241163739610044, 4.0: 0.7250252214062713, 4.2: 0.7261076041592891, 4.4: 0.7274016469831381, 4.6: 0.7284684102652901, 4.8: 0.7286547424518854}\n",
      "\n",
      "gama =  0.0006  every c with the best scor ++>\n",
      "{0.2: 0.5854948773037958, 0.4: 0.6328803750117055, 0.6: 0.6504617574020473, 0.8: 0.6634780352981254, 1.0: 0.6720695193456785, 1.2: 0.684981187768976, 1.4: 0.6893641402612118, 1.6: 0.6939662540236298, 1.8: 0.6986236750491481, 2.0: 0.7014637337205152, 2.2: 0.7066695669351264, 2.4: 0.7103432985674762, 2.6: 0.7148438009102622, 2.8: 0.7190446031696688, 3.0: 0.7224629301631483, 3.2: 0.7244466930217833, 3.4: 0.7253233194053692, 3.6: 0.7262448425030917, 3.8: 0.7282915069793554, 4.0: 0.7286989678560313, 4.2: 0.7295987052777064, 4.4: 0.729700907900156, 4.6: 0.728839765010967, 4.8: 0.7269456440871728}\n",
      "\n",
      "gama =  0.0007  every c with the best scor ++>\n",
      "{0.2: 0.5946488904232026, 0.4: 0.6384057011560245, 0.6: 0.6599164289820438, 0.8: 0.6685025631503055, 1.0: 0.6833903949857174, 1.2: 0.6895301754922634, 1.4: 0.695030876123822, 1.6: 0.6997603533618901, 1.8: 0.7038178208541237, 2.0: 0.7090209564240542, 2.2: 0.7137804083363378, 2.4: 0.7184028906632645, 2.6: 0.7224229041828533, 2.8: 0.7246943400984728, 3.0: 0.7261863977098104, 3.2: 0.7272487553719788, 3.4: 0.7286689584215282, 3.6: 0.729549878734423, 3.8: 0.7297909304276433, 4.0: 0.7285595669255386, 4.2: 0.7270644201868888, 4.4: 0.7271091120881921, 4.6: 0.7282132858435635, 4.8: 0.7289091204247816}\n",
      "\n",
      "gama =  0.0008  every c with the best scor ++>\n",
      "{0.2: 0.6014847549956549, 0.4: 0.6456631797381083, 0.6: 0.6635885088666289, 0.8: 0.6755649614669796, 1.0: 0.6873810583881346, 1.2: 0.6940745788808915, 1.4: 0.6994703929200652, 1.6: 0.7042065631033085, 1.8: 0.7098483339366174, 2.0: 0.7153625120024629, 2.2: 0.7212513658385986, 2.4: 0.7240662458021191, 2.6: 0.7252797447783053, 2.8: 0.7274319098490317, 3.0: 0.7279343216396034, 3.2: 0.7287472728821909, 3.4: 0.7293016638430504, 3.6: 0.727200554643691, 3.8: 0.7276289859209972, 4.0: 0.727994498388477, 4.2: 0.7289439991182387, 4.4: 0.7291152976413895, 4.6: 0.7285656968564699, 4.8: 0.7291117826305167}\n",
      "\n",
      "gama =  0.0009  every c with the best scor ++>\n",
      "{0.2: 0.6102109729445867, 0.4: 0.6500042262237313, 0.6: 0.6672026568404629, 0.8: 0.6848700894551221, 1.0: 0.6909658171589383, 1.2: 0.6984706672155435, 1.4: 0.7031855797860841, 1.6: 0.7094573485855542, 1.8: 0.7160176854221496, 2.0: 0.7214627779416609, 2.2: 0.724761629425042, 2.4: 0.7260667570785116, 2.6: 0.7276290878601898, 2.8: 0.7288546902266576, 3.0: 0.7291387445939479, 3.2: 0.7271750123105831, 3.4: 0.7277612490917467, 3.6: 0.7283783275476785, 3.8: 0.728722589431482, 4.0: 0.7286516842238087, 4.2: 0.7285731930186825, 4.4: 0.7285219604001503, 4.6: 0.7281423613383342, 4.8: 0.7273329792391356}\n",
      "\n",
      "gama =  0.001  every c with the best scor ++>\n",
      "{0.2: 0.6169826445984067, 0.4: 0.6562682879709414, 0.6: 0.670604064893144, 0.8: 0.6876276565380912, 1.0: 0.6959080238544995, 1.2: 0.7009747535817987, 1.4: 0.7080805130665981, 1.6: 0.7154102810231653, 1.8: 0.7211036020247954, 2.0: 0.7245262225117743, 2.2: 0.7263215958883104, 2.4: 0.7275166574993656, 2.6: 0.7285252323646957, 2.8: 0.7280984976472638, 3.0: 0.7273794804039594, 3.2: 0.7277407272276466, 3.4: 0.7286145191161955, 3.6: 0.7289010549799191, 3.8: 0.7288160339074499, 4.0: 0.728126775173793, 4.2: 0.7274815533490058, 4.4: 0.7270033046404927, 4.6: 0.7261908834094681, 4.8: 0.7254489710016871}\n",
      "\n",
      "gama =  0.0011  every c with the best scor ++>\n",
      "{0.2: 0.6261059430921742, 0.4: 0.6612713646298489, 0.6: 0.677199620396518, 0.8: 0.6907472094521465, 1.0: 0.698700403074844, 1.2: 0.7053713031672537, 1.4: 0.7126918795815081, 1.6: 0.7199301920220323, 1.8: 0.7240712024496763, 2.0: 0.7264662308614617, 2.2: 0.7276886444571051, 2.4: 0.7279526357753219, 2.6: 0.7277525787351308, 2.8: 0.72752352357347, 3.0: 0.728657800353213, 3.2: 0.7284035413308568, 3.4: 0.7289339016483063, 3.6: 0.7279455250972644, 3.8: 0.7277636656400109, 4.0: 0.7268007726230572, 4.2: 0.7263279241128353, 4.4: 0.7253571825504623, 4.6: 0.7247221882197132, 4.8: 0.7247121795125204}\n",
      "\n",
      "gama =  0.0012  every c with the best scor ++>\n",
      "{0.2: 0.6320955728132003, 0.4: 0.6635120459100974, 0.6: 0.6842604055107628, 0.8: 0.6937780710184722, 1.0: 0.7008633413405144, 1.2: 0.7090990826270576, 1.4: 0.7170552479173263, 1.6: 0.7232569483326983, 1.8: 0.7254044674246942, 2.0: 0.7275960367219843, 2.2: 0.7276987166652253, 2.4: 0.727169952279124, 2.6: 0.72809672456677, 2.8: 0.7283599616326943, 3.0: 0.728622843014282, 3.2: 0.7288533198496685, 3.4: 0.7280248939331355, 3.6: 0.7271729836946522, 3.8: 0.7261281874004933, 4.0: 0.7253786294816771, 4.2: 0.7245567387465961, 4.4: 0.7242680774430288, 4.6: 0.7238020675982757, 4.8: 0.7225529094522911}\n",
      "\n",
      "gama =  0.0013  every c with the best scor ++>\n",
      "{0.2: 0.6347128997754625, 0.4: 0.6651004377972844, 0.6: 0.6870856979600501, 0.8: 0.6965670486235209, 1.0: 0.7037408005703549, 1.2: 0.713107142580057, 1.4: 0.7208707298897902, 1.6: 0.7247175177612202, 1.8: 0.7268411931745612, 2.0: 0.7276780541251118, 2.2: 0.727701794051405, 2.4: 0.7277110846307573, 2.6: 0.7286874238919963, 2.8: 0.7291141362462279, 3.0: 0.728768764350115, 3.2: 0.7274281513066314, 3.4: 0.7269078801523741, 3.6: 0.7256137300132199, 3.8: 0.7250555516828654, 4.0: 0.7245349627030413, 4.2: 0.7238398885071627, 4.4: 0.7222422362646733, 4.6: 0.7212979711415541, 4.8: 0.7192367022796018}\n",
      "\n",
      "gama =  0.0014  every c with the best scor ++>\n",
      "{0.2: 0.6373574522194134, 0.4: 0.6673604985669404, 0.6: 0.6891851280498835, 0.8: 0.6989264421523541, 1.0: 0.707499222099595, 1.2: 0.7166460936472763, 1.4: 0.7233223032431875, 1.6: 0.7259637483512447, 1.8: 0.7277423177701092, 2.0: 0.7273831203873842, 2.2: 0.727345928034713, 2.4: 0.7279587437860497, 2.6: 0.7288208494755037, 2.8: 0.7284271069028868, 3.0: 0.7270140421968838, 3.2: 0.7267508826573694, 3.4: 0.7256928571281651, 3.6: 0.724789178078719, 3.8: 0.7238663752215775, 4.0: 0.7232419993687893, 4.2: 0.7211854463468321, 4.4: 0.719858435053607, 4.6: 0.717971230903194, 4.8: 0.7167464959268349}\n",
      "\n",
      "gama =  0.0015  every c with the best scor ++>\n",
      "{0.2: 0.6398933852123182, 0.4: 0.6698660101350975, 0.6: 0.6907595205298341, 0.8: 0.7008245852008452, 1.0: 0.710550676110211, 1.2: 0.7195063808987223, 1.4: 0.724523773235299, 1.6: 0.7266798250568913, 1.8: 0.7276022589455717, 2.0: 0.7274292188345994, 2.2: 0.7283765484179376, 2.4: 0.728589505612353, 2.6: 0.7280264913640626, 2.8: 0.7271981621570318, 3.0: 0.7263013083303782, 3.2: 0.7249823316451436, 3.4: 0.7246628406058551, 3.6: 0.7236886388931987, 3.8: 0.7221541478533215, 4.0: 0.7206852667002845, 4.2: 0.7190169443628278, 4.4: 0.7174200546338736, 4.6: 0.7156771322088098, 4.8: 0.7149951103826273}\n",
      "\n",
      "gama =  0.0016  every c with the best scor ++>\n",
      "{0.2: 0.644588250100179, 0.4: 0.673043139326887, 0.6: 0.693249779532904, 0.8: 0.7027652133775795, 1.0: 0.7137166147847016, 1.2: 0.7220735440631688, 1.4: 0.7255974550999402, 1.6: 0.7272578918310855, 1.8: 0.7275464255215813, 2.0: 0.7280314463334602, 2.2: 0.728398190321532, 2.4: 0.7281229006164491, 2.6: 0.7271664084540528, 2.8: 0.7266231912468573, 3.0: 0.7244803309714289, 3.2: 0.7241250405820592, 3.4: 0.723330835670527, 3.6: 0.7216163993208966, 3.8: 0.7198028718904224, 4.0: 0.717978281725316, 4.2: 0.7161757822389245, 4.4: 0.7144794143579336, 4.6: 0.7138055310510997, 4.8: 0.7131488473812615}\n",
      "\n",
      "gama =  0.0017  every c with the best scor ++>\n",
      "{0.2: 0.646608320517678, 0.4: 0.6778063650290853, 0.6: 0.6956719069727395, 0.8: 0.7055630952336023, 1.0: 0.7165292198360491, 1.2: 0.723148315991311, 1.4: 0.7266276946983463, 1.6: 0.7271004795310341, 1.8: 0.7272597336637345, 2.0: 0.7276399913827948, 2.2: 0.7281010410613462, 2.4: 0.727888025833983, 2.6: 0.726250336386455, 2.8: 0.7251850964122738, 3.0: 0.7240854597043158, 3.2: 0.7231190438375839, 3.4: 0.7217524010719766, 3.6: 0.7196360901730573, 3.8: 0.7175016239777899, 4.0: 0.7159191282599315, 4.2: 0.7148930917635022, 4.4: 0.7135735615876844, 4.6: 0.7129706414514811, 4.8: 0.7119207662841248}\n",
      "\n",
      "gama =  0.0018  every c with the best scor ++>\n",
      "{0.2: 0.6486850395466583, 0.4: 0.6822276911428036, 0.6: 0.697665609403131, 0.8: 0.7077464101703063, 1.0: 0.7193374602520789, 1.2: 0.7245524620750807, 1.4: 0.726806899538074, 1.6: 0.727490501941144, 1.8: 0.7276768183037441, 2.0: 0.7280049894302283, 2.2: 0.7276480893774064, 2.4: 0.7266354350002979, 2.6: 0.7253154762416066, 2.8: 0.7240184394054447, 3.0: 0.7230550328747068, 3.2: 0.7215257129380581, 3.4: 0.719368183221867, 3.6: 0.717734625022836, 3.8: 0.7153661478362681, 4.0: 0.7141909277948675, 4.2: 0.7136847259463615, 4.4: 0.7124894003866953, 4.6: 0.7123972558720726, 4.8: 0.7118602425652956}\n",
      "\n",
      "gama =  0.0019  every c with the best scor ++>\n",
      "{0.2: 0.6513656527328628, 0.4: 0.6854137850369814, 0.6: 0.699130343980727, 0.8: 0.7103028343328159, 1.0: 0.7208278208032538, 1.2: 0.7252042540028969, 1.4: 0.727227961914582, 1.6: 0.7271757005408777, 1.8: 0.7277188373143921, 2.0: 0.727964604972293, 2.2: 0.7271302823380693, 2.4: 0.7263687330290346, 2.6: 0.724295696409576, 2.8: 0.7234357687022117, 3.0: 0.7221794914003502, 3.2: 0.7194961955968124, 3.4: 0.7172191492946348, 3.6: 0.715577943568215, 3.8: 0.7141281040137429, 4.0: 0.7134080440021482, 4.2: 0.7126013950587853, 4.4: 0.7122727992011322, 4.6: 0.7121773113532743, 4.8: 0.7114878202406227}\n",
      "\n",
      "gama =  0.002  every c with the best scor ++>\n",
      "{0.2: 0.6540231822407652, 0.4: 0.6870749536119709, 0.6: 0.7006415102525032, 0.8: 0.7125338096105154, 1.0: 0.7223301810604457, 1.2: 0.7260606504871442, 1.4: 0.727142605885154, 1.6: 0.7273998757624063, 1.8: 0.7279498552282342, 2.0: 0.727346500505006, 2.2: 0.7263570839439105, 2.4: 0.7248045514156549, 2.6: 0.7235096424239329, 2.8: 0.7220002922895461, 3.0: 0.7198830683769073, 3.2: 0.717527141691034, 3.4: 0.71556074678155, 3.6: 0.7139687093212164, 3.8: 0.7133187879840466, 4.0: 0.7124741915872699, 4.2: 0.7125398530479157, 4.4: 0.7119263648411784, 4.6: 0.7116496010805247, 4.8: 0.7110268446174572}\n",
      "\n",
      "\n",
      "\n",
      "The Best C is 3.8 and the best gama is 0.0007 which it has max score = 0.7297909304276433 \n"
     ]
    }
   ],
   "source": [
    "def best_of_C(gama = 1):\n",
    "    c_params = {}\n",
    "    for c in range(1, 25):  # range from 0.2 to 5\n",
    "        c = c/5\n",
    "        Model = SVR(kernel='rbf', C=c, gamma=gama).fit(X_train, y_train)\n",
    "        # y_pred = Model.predict(X_val)\n",
    "        c_params[c] = Model.score(X_val, y_val)\n",
    "        \n",
    "    print(c_params, end='\\n\\n')\n",
    "    max_score = max(c_params.values())\n",
    "    c = [k for k, v in c_params.items() if v == max_score][0]\n",
    "    return c, max_score \n",
    "\n",
    "def best_of_gamas():\n",
    "    gama_param = {}\n",
    "    for gama in range(1,21):\n",
    "        gama = gama/10000\n",
    "        print('gama = ', gama, ' every c with the best scor ++>')\n",
    "        gama_param[gama] = best_of_C(gama= gama)\n",
    "    \n",
    "        \n",
    "    max_score = max(np.array(list(gama_param.values()))[:,1])\n",
    "    best = [[k, v[0]] for k, v in gama_param.items() if v[1] == max_score]\n",
    "    best_c = best[0][1]\n",
    "    best_gama = best[0][0]\n",
    "    print( f'\\n\\nThe Best C is {best_c} and the best gama is {best_gama} which it has max score = {max_score} '  )\n",
    "    \n",
    "best_of_gamas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Different values of the epsilon (start with 0.01 then increase it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value of epsilon 0.01 which it has max score = 0.8143749162960436 \n",
      "value of epsilon 0.02 which it has max score = 0.8144951749227394 \n",
      "value of epsilon 0.03 which it has max score = 0.81090558183944 \n",
      "value of epsilon 0.04 which it has max score = 0.8022902408116205 \n",
      "value of epsilon 0.05 which it has max score = 0.7874133407259055 \n",
      "value of epsilon 0.06 which it has max score = 0.7673101360165266 \n",
      "value of epsilon 0.07 which it has max score = 0.7487472936506776 \n",
      "value of epsilon 0.08 which it has max score = 0.7284423668366342 \n",
      "value of epsilon 0.09 which it has max score = 0.7102900690668772 \n",
      "value of epsilon 0.1 which it has max score = 0.6926408995231323 \n",
      "value of epsilon 0.11 which it has max score = 0.6761303047393548 \n",
      "value of epsilon 0.12 which it has max score = 0.6656152825837622 \n",
      "value of epsilon 0.13 which it has max score = 0.6546822523448494 \n",
      "value of epsilon 0.14 which it has max score = 0.6433917099550905 \n",
      "value of epsilon 0.15 which it has max score = 0.6330968831431802 \n",
      "value of epsilon 0.16 which it has max score = 0.6226516332877714 \n",
      "value of epsilon 0.17 which it has max score = 0.6131280148148766 \n",
      "value of epsilon 0.18 which it has max score = 0.6085378462731954 \n",
      "value of epsilon 0.19 which it has max score = 0.6009679469496667 \n"
     ]
    }
   ],
   "source": [
    "for eps in range(1,20):\n",
    "    eps = eps/100\n",
    "    Model = SVR(epsilon=eps).fit(X_train, y_train)\n",
    "    score = Model.score(X_val, y_val)\n",
    "    print(f'value of epsilon {eps} which it has max score = {score} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we note the score decrease if the epsilon is increase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. linear regression with explicit basis expansion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.45 EiB for an array with shape (896, 393812684240976) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mh:\\ITIData\\ITI AI-Pro Track\\ML\\my_work\\Lab_SVM\\lab1_mohamed_mosa - Copy.ipynb Cell 25'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/h%3A/ITIData/ITI%20AI-Pro%20Track/ML/my_work/Lab_SVM/lab1_mohamed_mosa%20-%20Copy.ipynb#ch0000047?line=0'>1</a>\u001b[0m x_poly \u001b[39m=\u001b[39m PolynomialFeatures(\u001b[39m10\u001b[39;49m)\u001b[39m.\u001b[39;49mfit_transform(X_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/h%3A/ITIData/ITI%20AI-Pro%20Track/ML/my_work/Lab_SVM/lab1_mohamed_mosa%20-%20Copy.ipynb#ch0000047?line=1'>2</a>\u001b[0m x_val_poly \u001b[39m=\u001b[39m PolynomialFeatures(\u001b[39m10\u001b[39m)\u001b[39m.\u001b[39mfit_transform(X_val)\n\u001b[0;32m      <a href='vscode-notebook-cell:/h%3A/ITIData/ITI%20AI-Pro%20Track/ML/my_work/Lab_SVM/lab1_mohamed_mosa%20-%20Copy.ipynb#ch0000047?line=3'>4</a>\u001b[0m model_linear \u001b[39m=\u001b[39m LinearRegression()\u001b[39m.\u001b[39mfit(x_poly, y_train)\n",
      "File \u001b[1;32mc:\\Users\\midom\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:852\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/midom/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/base.py?line=847'>848</a>\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/midom/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/base.py?line=848'>849</a>\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/midom/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/base.py?line=849'>850</a>\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/midom/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/base.py?line=850'>851</a>\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/midom/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/base.py?line=851'>852</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39;49mtransform(X)\n\u001b[0;32m    <a href='file:///c%3A/Users/midom/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/base.py?line=852'>853</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/midom/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/base.py?line=853'>854</a>\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/midom/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/base.py?line=854'>855</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\midom\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py:421\u001b[0m, in \u001b[0;36mPolynomialFeatures.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/midom/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/preprocessing/_polynomial.py?line=416'>417</a>\u001b[0m     XP \u001b[39m=\u001b[39m sparse\u001b[39m.\u001b[39mhstack(columns, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype)\u001b[39m.\u001b[39mtocsc()\n\u001b[0;32m    <a href='file:///c%3A/Users/midom/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/preprocessing/_polynomial.py?line=417'>418</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/midom/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/preprocessing/_polynomial.py?line=418'>419</a>\u001b[0m     \u001b[39m# Do as if _min_degree = 0 and cut down array after the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/midom/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/preprocessing/_polynomial.py?line=419'>420</a>\u001b[0m     \u001b[39m# computation, i.e. use _n_out_full instead of n_output_features_.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/midom/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/preprocessing/_polynomial.py?line=420'>421</a>\u001b[0m     XP \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mempty(\n\u001b[0;32m    <a href='file:///c%3A/Users/midom/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/preprocessing/_polynomial.py?line=421'>422</a>\u001b[0m         shape\u001b[39m=\u001b[39;49m(n_samples, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_n_out_full), dtype\u001b[39m=\u001b[39;49mX\u001b[39m.\u001b[39;49mdtype, order\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49morder\n\u001b[0;32m    <a href='file:///c%3A/Users/midom/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/preprocessing/_polynomial.py?line=422'>423</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/midom/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/preprocessing/_polynomial.py?line=424'>425</a>\u001b[0m     \u001b[39m# What follows is a faster implementation of:\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/midom/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/preprocessing/_polynomial.py?line=425'>426</a>\u001b[0m     \u001b[39m# for i, comb in enumerate(combinations):\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/midom/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/preprocessing/_polynomial.py?line=426'>427</a>\u001b[0m     \u001b[39m#     XP[:, i] = X[:, comb].prod(1)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/midom/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/preprocessing/_polynomial.py?line=436'>437</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/midom/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/preprocessing/_polynomial.py?line=437'>438</a>\u001b[0m     \u001b[39m# degree 0 term\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/midom/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/preprocessing/_polynomial.py?line=438'>439</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minclude_bias:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.45 EiB for an array with shape (896, 393812684240976) and data type float64"
     ]
    }
   ],
   "source": [
    "x_poly = PolynomialFeatures(10).fit_transform(X_train)\n",
    "x_val_poly = PolynomialFeatures(10).fit_transform(X_val)\n",
    "\n",
    "model_linear = LinearRegression().fit(x_poly, y_train)\n",
    "print('score = ', model_linear.score(x_val_poly, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have an memory error with higher degree "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. SVR using the polynomial kernel with degree 50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we resat the degree of function to 50 degree and not change in any parameters the score is not good but not found error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value of epsilon  which it has max score = -56522.59265236496 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "Model = SVR(kernel='poly', degree=50).fit(X_train, y_train)\n",
    "y_pred = Model.predict(X_val)\n",
    "score = Model.score(X_val, y_val)\n",
    "print(f'value of epsilon  which it has max score = {score} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you keet the degree as 50 and change the C and gamma parameters. we achive score 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value of epsilon  which it has max score = -0.9563957883932184 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "Model = SVR(kernel='poly', degree=50, C=0.1, gamma=0.01154).fit(X_train, y_train)\n",
    "y_pred = Model.predict(X_val)\n",
    "score = Model.score(X_val, y_val)\n",
    "print(f'value of epsilon  which it has max score = {score} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we reduse the degree to 15 and make C parameter 2. we achive score 98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value of epsilon  which it has max score = -0.9829230425863322 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "Model = SVR(kernel='poly', degree=15, C=2).fit(X_train, y_train)\n",
    "y_pred = Model.predict(X_val)\n",
    "score = Model.score(X_val, y_val)\n",
    "print(f'value of epsilon  which it has max score = {score} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we try to put the best value of c and gamma parameters with degree 50 the score is Died."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value of epsilon  which it has max score = 0.04275365889061411 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "Model = SVR(kernel='poly', degree=50, C=0.6, gamma=0.01).fit(X_train, y_train)\n",
    "y_pred = Model.predict(X_val)\n",
    "score = Model.score(X_val, y_val)\n",
    "print(f'value of epsilon  which it has max score = {score} ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7910926ca573e309c39282ee76a67e38cda1cbc97ea98e7be2faec206966ea43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
